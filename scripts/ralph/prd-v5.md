# V5 PRD: LinkedIn 포스트 품질 피드백 & 빠른 반복

## Context

V4에서 백엔드 품질을 근본적으로 개선했다 (지침서 완성, 시나리오 필터링, 페르소나, 학습 루프, 검증 강화).
그러나 사용자가 이 개선을 **체감하기 어렵다**:

1. **평가 결과가 보이지 않음** — `evaluation` JSON이 DB에 저장되지만 UI에 렌더링되지 않음. 사용자는 글이 좋은지 나쁜지 알 수 없음
2. **수정 반복이 느림** — 매번 채팅에 텍스트를 직접 타이핑해야 함. "훅 강화해줘" 같은 반복 요청을 원클릭으로 처리 불가
3. **시나리오 선택 근거 없음** — AI가 감지한 confidence(0.85 등)가 UI에 표시되지 않음. 대안 시나리오 추천도 없음
4. **참고 포스트 활용 불투명** — V4에서 scenario 컬럼을 추가했지만, UI에서 시나리오별 태깅/필터가 없음
5. **여러 드래프트 비교 불가** — 같은 기사에 여러 버전이 있어도 하나씩만 볼 수 있음

## 변경 파일

| 파일 | Story | 변경 내용 |
|------|-------|----------|
| `web/templates/articles/detail.html` | V5-001~004 | 스코어카드, 빠른 수정, 신뢰도 배지, 비교 UI |
| `web/api/linkedin.py` | V5-002, V5-003 | 빠른 수정 엔드포인트, 시나리오 대안 API |
| `web/services/linkedin_service.py` | V5-003 | 대안 시나리오 추천 메서드 |
| `web/api/settings.py` | V5-004 | 참고 포스트 시나리오 태깅 API |
| `web/templates/settings/guidelines.html` | V5-004 | 참고 포스트 시나리오 UI |

---

## V5-001: 평가 결과 시각적 스코어카드 (Priority 1)

**핵심**: 사용자가 글 품질을 한눈에 파악할 수 없음. evaluation JSON을 시각적으로 렌더링.

**변경사항**:
1. `detail.html` — `renderEvaluationScorecard(evalJson, containerId)` JS 함수 추가:
   - overall_score를 큰 숫자 + 색상 배지로 표시 (≥80 녹색, ≥60 노란색, <60 빨간색)
   - items를 카테고리별 (문체/구조/금지/형식) 그룹핑
   - 각 항목: PASS(✓ 녹색) / FAIL(✗ 빨간색) 배지 + rule + comment
   - summary를 하단에 텍스트로 표시
2. 드래프트 카드에 스코어카드 토글 버튼 추가 ("평가" 버튼)
3. Agent 모드 완료 후 step 5 결과에도 스코어카드 자동 렌더링
4. Simple 모드 드래프트도 evaluation이 있으면 스코어카드 표시

**검증 기준**:
- evaluation JSON이 있는 드래프트에 시각적 스코어카드 표시됨
- PASS/FAIL 항목이 색상으로 구분됨
- Agent 모드와 Simple 모드 모두 동작

---

## V5-002: 빠른 수정 팔레트 (Priority 2)

**핵심**: "훅 강화해줘", "좀 더 짧게" 같은 반복 수정 요청을 원클릭으로 처리.

**변경사항**:
1. `detail.html` — 드래프트 채팅 입력 영역 위에 빠른 수정 버튼 배열 추가:
   - "훅 더 강렬하게" → 프롬프트: "첫 1-2줄(훅)을 더 임팩트 있게 수정해주세요. 숫자나 구체적 사실로 시작하세요."
   - "본문 축약" → 프롬프트: "전체 글을 1200-1400자로 축약해주세요. 핵심 메시지는 유지하면서 불필요한 부분을 줄이세요."
   - "톤 부드럽게" → 프롬프트: "전체적으로 톤을 부드럽게 조정해주세요. 더 대화체에 가깝게, 딱딱한 표현을 자연스럽게 바꾸세요."
   - "데이터 추가" → 프롬프트: "구체적인 숫자, 통계, 데이터 포인트를 더 추가해주세요."
   - "마무리 교체" → 프롬프트: "마지막 1-2문장을 다른 스타일로 교체해주세요. 현재 마무리와 다른 접근법으로."
2. 버튼 클릭 → 기존 `sendDraftChat()` / `sendChatMessage()` 호출 (프롬프트 자동 입력)
3. Agent 모드 채팅 영역에도 동일한 팔레트 추가

**검증 기준**:
- 채팅 입력 위에 5개 버튼 표시됨
- 버튼 클릭 시 해당 수정 프롬프트가 채팅으로 전송되고 결과 반영됨
- 드래프트 기반 채팅과 Agent 세션 채팅 모두 동작

---

## V5-003: 시나리오 감지 신뢰도 + 대안 추천 (Priority 3)

**핵심**: 시나리오 선택에 AI의 근거를 보여주고, 대안을 제시.

**변경사항**:
1. `linkedin_service.py` — `detect_scenario_with_alternatives(article)` 메서드 추가:
   - 기존 `detect_scenario_detailed()` 활용
   - confidence < 0.75이면 2순위 시나리오도 반환
   - 반환: `{primary: {scenario, confidence, reason}, alternatives: [{scenario, confidence, reason}]}`
2. `web/api/linkedin.py` — `GET /api/linkedin/scenario/{article_id}` 엔드포인트 추가:
   - 시나리오 감지 결과 + 대안 반환
3. `detail.html` — 시나리오 선택 UI 개선:
   - 추천 시나리오 옆에 confidence 배지 표시 (예: "85%")
   - confidence < 0.75이면 "다른 시나리오도 고려" 섹션 표시
   - 대안 시나리오 클릭 시 해당 시나리오로 전환

**검증 기준**:
- 시나리오 추천 시 confidence % 표시됨
- 낮은 confidence일 때 대안 시나리오 표시됨
- 대안 클릭 시 시나리오 변경 가능

---

## V5-004: 참고 포스트 시나리오 태깅 UI (Priority 4)

**핵심**: V4에서 ReferencePost.scenario 컬럼을 추가했지만 UI가 없음. 시나리오별 관리 기능 추가.

**변경사항**:
1. `web/api/settings.py`:
   - 참고 포스트 등록 시 scenario 필드 수용 (기존 API 확장)
   - `PATCH /api/settings/reference-posts/{id}/scenario` 엔드포인트 추가
   - `GET /api/settings/reference-posts?scenario=D` 필터링 지원
2. `web/templates/settings/guidelines.html` — 참고 포스트 카드에:
   - 시나리오 배지 표시 (A~F, 색상 구분)
   - 시나리오 미지정 시 "태그 없음" 회색 배지
   - 드롭다운으로 시나리오 변경 기능
   - 시나리오별 필터 탭 (전체 / A / B / C / D / E / F)

**검증 기준**:
- 참고 포스트에 시나리오 배지 표시됨
- 드롭다운으로 시나리오 변경 가능
- 시나리오별 필터링 동작

---

## V5-005: 드래프트 나란히 비교 (Priority 5)

**핵심**: 같은 기사에 여러 드래프트가 있을 때, 최적 버전을 고르기 어려움.

**변경사항**:
1. `detail.html` — "드래프트 비교" 버튼 추가 (드래프트 2개 이상일 때만 표시):
   - 클릭 시 비교 모달/패널 열림
   - 2개 드래프트를 나란히 표시 (side-by-side)
   - 각 드래프트: 훅(첫 줄) 하이라이트, 글자수, 시나리오, 평가 점수 요약
   - "이 버전 사용" 버튼으로 선택
2. 비교 항목:
   - 글자수 비교 바
   - 훅 비교 (첫 줄 나란히)
   - 평가 점수 비교 (overall_score)
   - 구조 비교 (단락 수)

**검증 기준**:
- 드래프트 2개 이상일 때 "비교" 버튼 표시
- 나란히 비교 UI에서 핵심 지표 확인 가능
- "이 버전 사용" 클릭 시 해당 드래프트가 final로 마킹

---

## 구현 순서

```
V5-001 (스코어카드)        ← 기반 (evaluation 렌더링)
  ↓
V5-002 (빠른 수정 팔레트)  ← V5-001 이후 (스코어카드 보고 수정)
V5-003 (시나리오 신뢰도)   ← 독립
  ↓
V5-004 (참고 포스트 태깅)  ← 독립
V5-005 (드래프트 비교)     ← 독립
```

## 검증

1. `python -m py_compile` 모든 수정 파일
2. Simple 모드 드래프트 생성 → 스코어카드 렌더링 확인
3. 빠른 수정 "훅 강화" 클릭 → 채팅 수정 반영 확인
4. 시나리오 감지 → confidence % 표시 + 낮을 때 대안 표시 확인
5. 참고 포스트 시나리오 태깅 → 필터 동작 확인
6. 드래프트 2개 생성 → 비교 UI 동작 확인
