# Ralph Progress Log
Started: 2026년 2월 22일 일요일 11시 40분 59초 KST
---

## Codebase Patterns
- New SQLAlchemy columns: add to model + add ALTER TABLE in migrate_db() + add to to_dict()
- New API endpoint: add to web/api/<router>.py, import in web/api/__init__.py
- New page route: add to web/app.py, create template in web/templates/
- Templates use Tailwind CSS + HTMX, no JS frameworks
- Always py_compile after editing Python files
- chat_refine() in linkedin_agent.py is session-based; chat_refine_by_draft() in linkedin_service.py is draft-based (works after page refresh)
- LinkedInDraft stores agent-mode context: analysis, direction, review_notes, evaluation, guidelines_checklist, chat_history
- Agent sessions are in-memory (AgentSession dataclass in linkedin_agent.py); drafts persist in SQLite
- Draft card UI pattern: buttons in header div, toggleable panels (edit/chat) below draft content, per-draft JS with draftId parameter
- Agent result panel chat falls back to draft-based if session expired (agentSessionId null, agentDraftId set)
- Cannot nest f"""...""" inside an f-string — extract to variable first
- LinkedIn fold point for previews: ~210 chars or 3rd newline
- When adding Claude API prompts: build sections as variables, then compose in final f-string
- Hook Lab: copyHookText/startHookEdit/saveHookEdit/cancelHookEdit for per-card copy/edit; activateCustomHook/deactivateCustomHook for custom input mutual exclusivity
- event.stopPropagation() required on hook card buttons to prevent card selection on button click
- Evaluation JSON format: {overall_score, items: [{category, rule, pass, comment}], summary} — categories are 문체/구조/금지/형식
- Agent step 5 emits evaluation JSON as step_complete content; store in JS variable for reuse in agent result panel
- renderEvaluationScorecard(evalData, containerId) renders full visual scorecard; renderEvaluationTable(evalData) returns compact inline summary
- Draft card evaluation panels use lazy rendering with dataset.rendered flag to avoid re-rendering on toggle

---

## 2026-02-22 - V2-006
- What was implemented: Draft-based chat infrastructure — guidelines_checklist column + migration, _save_draft() saves checklist from agent session, chat_refine_by_draft() method in LinkedInService, POST /api/linkedin/drafts/{draft_id}/chat endpoint
- Files changed:
  - web/models/linkedin_draft.py — added guidelines_checklist column + to_dict()
  - web/database.py — added guidelines_checklist to migrate_db()
  - web/services/linkedin_agent.py — _save_draft() now saves guidelines_checklist
  - web/services/linkedin_service.py — added chat_refine_by_draft() method
  - web/api/linkedin.py — added POST /drafts/{draft_id}/chat endpoint
- **Learnings for future iterations:**
  - chat_refine_by_draft() is modeled after chat_refine() but uses DB state instead of in-memory session
  - PRD noted chat_refine_by_draft() already existed — it did not; had to create it from scratch
  - The draft-based chat loads guidelines_checklist, analysis, and chat_history from the draft record for context
  - ChatMessage pydantic model was already defined and reused for the new endpoint
---

## 2026-02-22 - V2-007
- What was implemented: Draft-based chat frontend + inline edit for existing draft cards in drafts-container
- Files changed:
  - web/templates/articles/detail.html — added chat/edit buttons, inline edit panel, draft chat panel, char count badges, JS functions, agent chat fallback to draft-based
- Features added:
  - Each draft card now has 편집(edit) and 채팅(chat) buttons
  - Inline edit panel per draft: startDraftEdit/saveDraftEdit/cancelDraftEdit → PATCH /api/linkedin/drafts/{draft_id}/content
  - Draft chat panel per draft: toggleDraftChat/sendDraftChat → POST /api/linkedin/drafts/{draft_id}/chat
  - Char count badge on each draft card, initialized on page load
  - Existing chat_history rendered when chat panel is opened
  - Agent result panel's sendChatMessage() falls back to draft-based chat when session is expired
- **Learnings for future iterations:**
  - All API endpoints (draft chat, draft content update) were already implemented in V2-006 — this was purely frontend work
  - draftChatHistories object is populated from Jinja2 template loop using draft.chat_history | tojson
  - getCharCountClass/getCharCountLabel helpers are shared between draft edit and agent edit
  - agent-result-panel chat checks agentSessionId first, then falls back to agentDraftId for draft-based chat
  - Template-only changes don't need py_compile
---

## 2026-02-22 - V2-008
- What was implemented: Hook Lab — generate multiple hooks before full draft, select a hook, then generate with that hook
- Files changed:
  - web/services/linkedin_service.py — added generate_hooks() method, added hook param to generate_draft() and _build_prompt()
  - web/api/linkedin.py — added POST /hooks/{article_id} endpoint, added hook query param to generate_draft and agent_start
  - web/services/linkedin_agent.py — added hook field to AgentSession, hook param to run(), hook section in _step_draft()
  - web/templates/articles/detail.html — Hook Lab UI (button, panel, cards, preview, actions), generateWithHook(), renderLinkedInPreview(), keyboard shortcut 'h'
- Features added:
  - generate_hooks(article, scenario, count=5): Claude generates 5 hooks with different styles (숫자형/질문형/역설/선언/스토리)
  - POST /api/linkedin/hooks/{article_id}?scenario=A: API endpoint returning hook options
  - Hook Lab panel: amber-themed UI with clickable hook cards, LinkedIn preview (210-char fold point), style badges
  - "이 훅으로 초안 생성" and "이 훅으로 Agent 모드" buttons after hook selection
  - hook parameter flows through generate_draft() → _build_prompt() and agent_start() → run() → _step_draft()
  - Replaced HTMX-based generate button with JS-based generateWithHook() to pass hook param
- **Learnings for future iterations:**
  - Cannot nest f"""...""" inside an f-string in Python — must extract to a variable first
  - renderLinkedInPreview() was NOT already in detail.html despite PRD notes — created from scratch
  - Hook styles mapped to color classes for visual differentiation in UI
  - selectedHookText is a module-level JS variable shared between hook lab and generation functions
  - LinkedIn fold point: ~210 chars or 3rd newline
---

## 2026-02-22 - V3-001
- What was implemented: Hook Lab UX enhancements — copy button, inline edit, and custom hook input for each hook card
- Files changed:
  - web/templates/articles/detail.html — added copy/edit buttons to renderHookCards(), inline edit panel per hook (textarea + char counter + save/cancel), custom hook input section with mutual exclusivity, activateCustomHook/deactivateCustomHook functions
- Features added:
  - 복사 button on each hook card: copies hook text, shows "Copied!" feedback with green highlight for 1.5s
  - 편집 button on each hook card: toggles inline textarea edit mode with char counter and save/cancel
  - saveHookEdit() updates generatedHooks[idx].hook, re-renders preview, and updates selectedHookText if selected
  - Custom hook input section (dashed border card with textarea, placeholder "나만의 훅을 직접 작성하세요 (1-3줄)")
  - Mutual exclusivity: selecting a hook card deactivates custom hook, typing in custom textarea deselects all hook cards
  - Custom hook feeds into existing generateWithHook()/startAgentMode() via shared selectedHookText variable
- **Learnings for future iterations:**
  - event.stopPropagation() is essential on buttons inside clickable card divs to prevent parent onclick
  - Custom hook uses onfocus + oninput handlers; onfocus calls activateCustomHook() which has guard for empty text
  - The hook-custom-section is initially hidden and revealed by renderHookCards() after hooks are loaded
  - No Python changes needed — purely frontend JS/HTML work
  - Jinja2 template syntax can be verified with `python3 -c "from jinja2 import Environment, FileSystemLoader; ..."`
---

## 2026-02-22 - V5-001
- What was implemented: Visual evaluation scorecard — replaces plain table with score circle + category-grouped PASS/FAIL badges
- Files changed:
  - web/templates/articles/detail.html — CSS for scorecard, renderEvaluationScorecard() JS function, "평가" toggle button on draft cards, agent result panel scorecard, step 5 compact summary
- Features added:
  - renderEvaluationScorecard(evalData, containerId): renders overall_score as big circle (green ≥80, yellow ≥60, red <60), items grouped by 문체/구조/금지/형식 with ✓/✗ badges
  - "평가" button in draft card header (indigo badge) — toggles scorecard panel below draft content
  - Agent mode step 5 stores evaluation in agentEvalData variable; handleAgentComplete() auto-renders scorecard in agent-scorecard-panel
  - renderEvaluationTable() simplified to compact inline circle + pass count for step timeline
  - Simple mode drafts with evaluation data show scorecard via same toggleScorecard() function
- **Learnings for future iterations:**
  - Evaluation JSON categories are: 문체, 구조, 금지, 형식 (in that order)
  - agent_complete event does NOT include evaluation data — must store from step 5's step_complete event
  - Lazy rendering with dataset.rendered flag prevents repeated DOM updates on toggle
  - No Python changes needed — purely frontend CSS/JS/HTML work
---

## 2026-02-22 - V5-002
- What was implemented: Quick Refine palette — 5 one-click refinement buttons above chat inputs
- Files changed:
  - web/templates/articles/detail.html — QUICK_REFINE_PROMPTS constant, sendQuickRefine() + renderQuickRefineButtons() JS functions, button containers in agent result panel chat and draft chat panels
- Features added:
  - 5 quick refine buttons: 훅 강화 / 본문 축약 / 톤 부드럽게 / 데이터 추가 / 마무리 교체
  - Buttons rendered as Tailwind pill-style (rounded-full, gray → purple on hover)
  - Each button has title attribute showing full prompt text on hover
  - Works in both agent result panel chat (sendChatMessage) and per-draft chat (sendDraftChat)
  - Buttons populated via renderQuickRefineButtons() on DOMContentLoaded
- **Learnings for future iterations:**
  - Avoid document.write() in templates — use DOMContentLoaded + innerHTML pattern instead
  - Template backtick strings in JS work well for prompt text (no escaping issues)
  - Quick refine uses same sendQuickRefine() function for both agent and draft targets, differentiated by targetType param
  - No Python changes needed — purely frontend JS/HTML work
---

## 2026-02-22 - V5-003
- What was implemented: Scenario confidence display + alternative scenario recommendation
- Files changed:
  - web/services/linkedin_service.py — modified _detect_scenario_with_claude() to return top-2 scenarios, added detect_scenario_with_alternatives() method
  - web/api/linkedin.py — added GET /api/linkedin/scenario/{article_id} endpoint
  - web/app.py — pass scenario_alternatives to template context
  - web/templates/articles/detail.html — confidence % badge on recommended scenario box + scenario buttons, alternative scenario section when confidence < 0.75
- **Learnings for future iterations:**
  - _detect_scenario_with_claude() now returns "alternatives" key with top-2 scenario data — cached in _scenario_cache
  - scenario_confidence is already passed to template from app.py (was unused before V5-003)
  - Jinja2 {% set conf_pct = (scenario_confidence * 100) | int %} for percentage conversion
  - Alternative scenario section uses same selectScenario() JS function for seamless switching
  - Color coding for confidence: green ≥80%, yellow ≥60%, red <60%
---

## 2026-02-22 - V5-004
- What was implemented: Reference post scenario tagging UI — scenario badges, dropdown changer, filter buttons, scenario field on creation
- Files changed:
  - web/api/settings.py — added ReferencePostScenarioUpdate model, scenario field to ReferencePostCreate, PATCH /reference-posts/{id}/scenario endpoint, scenario query filter on GET /reference-posts
  - web/templates/settings/guidelines.html — scenario filter buttons, scenario badge with dropdown on each ref card, scenario select on creation form, SCENARIO_STYLES JS constant, toggleScenarioDropdown/updateScenario/filterByScenario JS functions
- **Learnings for future iterations:**
  - ReferencePost.scenario column already existed from V4-002 — only needed API + UI work
  - save_reference_post() in GuidelinesLearner already accepted scenario param, auto-detects from analysis if not provided
  - Scenario color scheme: A=blue, B=green, C=purple, D=orange, E=rose, F=teal, unset=gray
  - Filter buttons use data-scenario attribute on ref-card divs for client-side filtering
  - Dropdown pattern: toggle on badge click + document click listener to close all dropdowns
  - event.stopPropagation() on badge button prevents document click from immediately closing dropdown
---
