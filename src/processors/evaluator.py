"""ê¸°ì‚¬ í‰ê°€ Agent - ë§í¬ë“œì¸ í¬ìŠ¤íŒ… ê°€ì¹˜ ë¶„ì„"""

import os
import json
from typing import TYPE_CHECKING, Optional
from dataclasses import dataclass

try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

if TYPE_CHECKING:
    from ..collectors.rss_collector import Article


@dataclass
class ArticleEvaluation:
    """ê¸°ì‚¬ í‰ê°€ ê²°ê³¼"""
    article_title: str
    article_url: str

    # í‰ê°€ ì ìˆ˜ (0-10)
    linkedin_potential: float      # ë§í¬ë“œì¸ engagement ì ì¬ë ¥
    insight_depth: float           # ì¸ì‚¬ì´íŠ¸ ê¹Šì´
    industry_relevance: float      # AI/Tech ì—…ê³„ ê´€ë ¨ì„±
    tpm_vc_relevance: float        # TPM/VC ê´€ì  ê´€ë ¨ì„±
    timeliness: float              # ì‹œì˜ì„±/ë‰´ìŠ¤ ê°€ì¹˜
    discussion_potential: float    # í† ë¡ /ë…¼ìŸ ìœ ë°œ ê°€ëŠ¥ì„±
    uniqueness: float              # ë…íŠ¹í•¨/ì°¨ë³„ì„±

    # ì¢…í•©
    total_score: float             # ê°€ì¤‘ í‰ê·  ì ìˆ˜
    recommended_angle: str         # ì¶”ì²œ í¬ìŠ¤íŒ… ê°ë„/ê´€ì 
    key_insight: str               # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    target_audience: str           # íƒ€ê²Ÿ ë…ìì¸µ
    hook_suggestion: str           # ì˜¤í”„ë‹ í›… ì œì•ˆ


class ArticleEvaluator:
    """ê¸°ì‚¬ë¥¼ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í‰ê°€í•˜ëŠ” ì „ë¬¸ Agent"""

    EVALUATION_PROMPT = """ë‹¹ì‹ ì€ AI/Tech íŠ¸ë Œë“œë¥¼ íŒ”ë¡œìš°í•˜ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤. ë§í¬ë“œì¸ì—ì„œ ê³µìœ í•  ë§Œí•œ ì½˜í…ì¸ ì¸ì§€ í‰ê°€í•©ë‹ˆë‹¤.

## í‰ê°€ ëŒ€ìƒ
ì œëª©: {title}
ì¶œì²˜: {source}
ì¹´í…Œê³ ë¦¬: {category}
ìš”ì•½: {summary}

## í‰ê°€ì í”„ë¡œí•„
- AIì™€ ìŠ¤íƒ€íŠ¸ì—…ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ëŒ
- ê³¼ì¥ëœ ë§ˆì¼€íŒ… í†¤ ì‹«ì–´í•¨
- ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ í¥ë¯¸ë¡œìš´ ë°œê²¬ì„ ì¢‹ì•„í•¨
- "í˜ì‹ ì ", "íšê¸°ì " ê°™ì€ ë‹¨ì–´ ì“°ëŠ” ê¸€ì€ íŒ¨ìŠ¤

## í‰ê°€ ê¸°ì¤€ (ê° 0-10ì )

1. curiosity_hook: ì œëª©ë§Œ ë´ë„ "ì–´? ì´ê±° ë­ì§€?" í•˜ê³  ê¶ê¸ˆí•´ì§€ëŠ”ê°€?
   - ë†’ìŒ: í´ë¦­ ì•ˆ í•˜ê³ ëŠ” ëª» ë°°ê¸°ëŠ” ì£¼ì œ
   - ë‚®ìŒ: "ê·¸ë ‡êµ¬ë‚˜" í•˜ê³  ìŠ¤í¬ë¡¤

2. practical_value: ì½ëŠ” ì‚¬ëŒì´ ë­”ê°€ ì–»ì–´ê°€ëŠ” ê²Œ ìˆëŠ”ê°€?
   - ë†’ìŒ: ìƒˆë¡œìš´ ì‹œê°, ìœ ìš©í•œ ì •ë³´, ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” íŒ
   - ë‚®ìŒ: ê·¸ëƒ¥ ë‰´ìŠ¤ ì „ë‹¬

3. discussion_trigger: ì‚¬ëŒë“¤ì´ ìê¸° ì˜ê²¬ì„ ë§í•˜ê³  ì‹¶ì–´ì§ˆ ë§Œí•œê°€?
   - ë†’ìŒ: "ë‚˜ëŠ” ì¢€ ë‹¤ë¥´ê²Œ ìƒê°í•˜ëŠ”ë°...", "ì´ê±° ì¨ë´¤ëŠ”ë°..."
   - ë‚®ìŒ: ë™ì˜/ë°˜ëŒ€í•  ì—¬ì§€ê°€ ì—†ëŠ” íŒ©íŠ¸ ë‚˜ì—´

4. explainability: ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ì£¼ì œì¸ê°€?
   - ë†’ìŒ: ë¹„ì „ë¬¸ê°€ë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª… ê°€ëŠ¥
   - ë‚®ìŒ: ë°°ê²½ì§€ì‹ ì—†ì´ëŠ” ì´í•´ ë¶ˆê°€

5. freshness: ì§€ê¸ˆ ì´ íƒ€ì´ë°ì— ê³µìœ í•´ì•¼ í•˜ëŠ” ì´ìœ ê°€ ìˆëŠ”ê°€?
   - ë†’ìŒ: ë°©ê¸ˆ ë‚˜ì˜¨ ì†Œì‹, ì—…ê³„ì—ì„œ í™”ì œì¸ ì£¼ì œ
   - ë‚®ìŒ: ì–¸ì œ ì˜¬ë ¤ë„ ìƒê´€ì—†ëŠ” ë‚´ìš©

6. shareability: ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ "ì´ê±° ë´¤ì–´?" í•˜ê³  ê³µìœ í•˜ê³  ì‹¶ì€ê°€?
   - ë†’ìŒ: ë™ë£Œí•œí…Œ ìŠ¬ë™ìœ¼ë¡œ ë³´ë‚´ê³  ì‹¶ìŒ
   - ë‚®ìŒ: í˜¼ì ì½ê³  ë

7. depth_potential: ë‹¨ìˆœ ìš”ì•½ì„ ë„˜ì–´ì„œ "ì™œ ì¤‘ìš”í•œì§€" ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
   - ë†’ìŒ: ë§¥ë½ê³¼ ì‹œì‚¬ì ì„ í’€ì–´ë‚¼ ìˆ˜ ìˆìŒ
   - ë‚®ìŒ: ìˆëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê²Œ ì „ë¶€

## ì‘ë‹µ í˜•ì‹ (JSON)
```json
{{
  "linkedin_potential": 7,
  "insight_depth": 8,
  "industry_relevance": 7,
  "tpm_vc_relevance": 8,
  "timeliness": 6,
  "discussion_potential": 7,
  "uniqueness": 6,
  "recommended_angle": "ì´ ê¸°ì‚¬ë¥¼ ì–´ë–¤ ì§ˆë¬¸ì´ë‚˜ ê´€ì ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì¢‹ì„ì§€ (ê²½í—˜ë‹´ ì—†ì´)",
  "key_insight": "ë»”í•˜ì§€ ì•Šì€, ì´ ê¸°ì‚¬ë§Œì˜ í•µì‹¬ í¬ì¸íŠ¸ í•œ ë¬¸ì¥",
  "target_audience": "ì´ ê¸€ì— ê´€ì‹¬ ê°€ì§ˆ ì‚¬ëŒë“¤ (êµ¬ì²´ì ìœ¼ë¡œ)",
  "hook_suggestion": "ìŠ¤í¬ë¡¤ ë©ˆì¶”ê²Œ í•˜ëŠ” ì²« ë¬¸ì¥ (ê³¼ì¥ ì—†ì´, í˜¸ê¸°ì‹¬ ìœ ë°œ)"
}}
```

JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

    def __init__(self):
        self.client = None
        if Anthropic and os.getenv("ANTHROPIC_API_KEY"):
            self.client = Anthropic()

    def evaluate_article(self, article: "Article") -> Optional[ArticleEvaluation]:
        """ë‹¨ì¼ ê¸°ì‚¬ í‰ê°€"""
        if not self.client:
            return None

        prompt = self.EVALUATION_PROMPT.format(
            title=article.title,
            source=article.source,
            category=article.category,
            summary=article.ai_summary or article.summary or "ìš”ì•½ ì—†ìŒ"
        )

        try:
            response = self.client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )

            result_text = response.content[0].text.strip()

            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]

            data = json.loads(result_text.strip())

            # ê°€ì¤‘ í‰ê·  ê³„ì‚° (TPM/VC ê´€ë ¨ì„±ê³¼ ì¸ì‚¬ì´íŠ¸ ê¹Šì´ì— ê°€ì¤‘ì¹˜)
            weights = {
                "linkedin_potential": 1.5,
                "insight_depth": 2.0,
                "industry_relevance": 1.0,
                "tpm_vc_relevance": 2.0,
                "timeliness": 1.0,
                "discussion_potential": 1.5,
                "uniqueness": 1.0
            }

            total_weight = sum(weights.values())
            total_score = sum(
                data.get(key, 5) * weight
                for key, weight in weights.items()
            ) / total_weight

            return ArticleEvaluation(
                article_title=article.title,
                article_url=article.url,
                linkedin_potential=data.get("linkedin_potential", 5),
                insight_depth=data.get("insight_depth", 5),
                industry_relevance=data.get("industry_relevance", 5),
                tpm_vc_relevance=data.get("tpm_vc_relevance", 5),
                timeliness=data.get("timeliness", 5),
                discussion_potential=data.get("discussion_potential", 5),
                uniqueness=data.get("uniqueness", 5),
                total_score=round(total_score, 2),
                recommended_angle=data.get("recommended_angle", ""),
                key_insight=data.get("key_insight", ""),
                target_audience=data.get("target_audience", ""),
                hook_suggestion=data.get("hook_suggestion", "")
            )

        except Exception as e:
            print(f"í‰ê°€ ì‹¤íŒ¨ [{article.title[:30]}]: {e}")
            return None

    def evaluate_all(self, articles: list["Article"]) -> list[ArticleEvaluation]:
        """ëª¨ë“  ê¸°ì‚¬ í‰ê°€ ë° ì •ë ¬"""
        evaluations = []

        print(f"ê¸°ì‚¬ í‰ê°€ ì‹œì‘ ({len(articles)}ê°œ)...")

        for i, article in enumerate(articles):
            evaluation = self.evaluate_article(article)
            if evaluation:
                evaluations.append(evaluation)

            if (i + 1) % 5 == 0:
                print(f"í‰ê°€ ì§„í–‰ ì¤‘: {i + 1}/{len(articles)}")

        # ì´ì  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        evaluations.sort(key=lambda x: x.total_score, reverse=True)

        print(f"í‰ê°€ ì™„ë£Œ: {len(evaluations)}ê°œ ê¸°ì‚¬")

        return evaluations

    def get_top_candidates(
        self,
        articles: list["Article"],
        top_n: int = 5,
        ensure_diversity: bool = True
    ) -> list[tuple["Article", ArticleEvaluation]]:
        """ë§í¬ë“œì¸ í¬ìŠ¤íŒ… ìƒìœ„ í›„ë³´ ì„ ì • (ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ì¥)"""
        evaluations = self.evaluate_all(articles)

        # í‰ê°€ ê²°ê³¼ì™€ ì›ë³¸ ê¸°ì‚¬ ë§¤ì¹­
        article_map = {a.url: a for a in articles}

        # URLë¡œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        url_to_category = {a.url: a.category for a in articles}

        if not ensure_diversity:
            # ê¸°ì¡´ ë°©ì‹: ë‹¨ìˆœ ì ìˆ˜ ìˆœ
            candidates = []
            for eval in evaluations[:top_n]:
                if eval.article_url in article_map:
                    candidates.append((article_map[eval.article_url], eval))
            return candidates

        # ë‹¤ì–‘ì„± ë³´ì¥ ë°©ì‹
        candidates = []
        used_urls = set()

        # í•„ìˆ˜ ì¹´í…Œê³ ë¦¬ (ê° 1ê°œ ì´ìƒ)
        # news ì¹´í…Œê³ ë¦¬ì—ëŠ” bigtech, news, community, korean í¬í•¨
        required_categories = {
            "research": 1,      # ì—°êµ¬ ë…¼ë¬¸ ìµœì†Œ 1ê°œ
            "news": 1,          # AI ë‰´ìŠ¤ ìµœì†Œ 1ê°œ
        }

        # ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ (research ì™¸ ëª¨ë“  ê²ƒ)
        news_categories = {"bigtech", "news", "community", "korean"}

        # 1ë‹¨ê³„: í•„ìˆ˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœê³  ì ìˆ˜ ì„ ì •
        for category, min_count in required_categories.items():
            if category == "news":
                # ë‰´ìŠ¤ëŠ” ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ íƒ
                category_evals = [
                    e for e in evaluations
                    if url_to_category.get(e.article_url) in news_categories
                    and e.article_url not in used_urls
                ]
            else:
                category_evals = [
                    e for e in evaluations
                    if url_to_category.get(e.article_url) == category
                    and e.article_url not in used_urls
                ]

            for eval in category_evals[:min_count]:
                if eval.article_url in article_map:
                    candidates.append((article_map[eval.article_url], eval))
                    used_urls.add(eval.article_url)

        # 2ë‹¨ê³„: ë‚˜ë¨¸ì§€ëŠ” ì ìˆ˜ ìˆœìœ¼ë¡œ ì±„ìš°ê¸°
        remaining_slots = top_n - len(candidates)
        for eval in evaluations:
            if remaining_slots <= 0:
                break
            if eval.article_url not in used_urls and eval.article_url in article_map:
                candidates.append((article_map[eval.article_url], eval))
                used_urls.add(eval.article_url)
                remaining_slots -= 1

        # ì ìˆ˜ ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x[1].total_score, reverse=True)

        return candidates

    def print_evaluation_report(self, evaluations: list[ArticleEvaluation], top_n: int = 5):
        """í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ë§í¬ë“œì¸ í¬ìŠ¤íŒ… í›„ë³´ í‰ê°€ ë¦¬í¬íŠ¸")
        print("=" * 60)

        for i, eval in enumerate(evaluations[:top_n], 1):
            print(f"\nğŸ† #{i} (ì ìˆ˜: {eval.total_score}/10)")
            print(f"ì œëª©: {eval.article_title[:60]}...")
            print(f"â”œâ”€ ë§í¬ë“œì¸ ì ì¬ë ¥: {eval.linkedin_potential}/10")
            print(f"â”œâ”€ ì¸ì‚¬ì´íŠ¸ ê¹Šì´: {eval.insight_depth}/10")
            print(f"â”œâ”€ TPM/VC ê´€ë ¨ì„±: {eval.tpm_vc_relevance}/10")
            print(f"â”œâ”€ í† ë¡  ì ì¬ë ¥: {eval.discussion_potential}/10")
            print(f"â”œâ”€ ì¶”ì²œ ê°ë„: {eval.recommended_angle[:50]}...")
            print(f"â””â”€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {eval.key_insight[:50]}...")

        print("\n" + "=" * 60)
