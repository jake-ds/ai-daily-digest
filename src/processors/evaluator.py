"""ê¸°ì‚¬ í‰ê°€ Agent - ë§í¬ë“œì¸ í¬ìŠ¤íŒ… ê°€ì¹˜ ë¶„ì„"""

import os
import json
from typing import TYPE_CHECKING, Optional
from dataclasses import dataclass

try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

if TYPE_CHECKING:
    from ..collectors.rss_collector import Article


@dataclass
class ArticleEvaluation:
    """ê¸°ì‚¬ í‰ê°€ ê²°ê³¼"""
    article_title: str
    article_url: str

    # í‰ê°€ ì ìˆ˜ (0-10) â€” 7ì°¨ì› í†µì¼
    curiosity: float               # í´ë¦­/ê´€ì‹¬ ìœ ë°œë ¥
    insight: float                 # ì‹¤ì§ˆì  ì¸ì‚¬ì´íŠ¸ ê¹Šì´
    relevance: float               # AI/Tech ì—…ê³„ ê´€ë ¨ì„±
    timeliness: float              # ì‹œì˜ì„±
    discussion: float              # í† ë¡  ìœ ë°œ ê°€ëŠ¥ì„±
    shareability: float            # ê³µìœ  ê°€ì¹˜
    depth: float                   # ë§¥ë½/ì‹œì‚¬ì  í•´ì„ ê°€ëŠ¥ì„±

    # ì¢…í•©
    ai_score: float                # ê°€ì¤‘ í‰ê·  ì¢…í•© ì ìˆ˜
    linkedin_potential: float      # LinkedIn íŠ¹í™” ê°€ì¤‘ í‰ê· 
    key_insight: str               # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    hook_suggestion: str           # ì˜¤í”„ë‹ í›… ì œì•ˆ


class ArticleEvaluator:
    """ê¸°ì‚¬ë¥¼ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í‰ê°€í•˜ëŠ” ì „ë¬¸ Agent"""

    EVALUATION_PROMPT = """ë‹¹ì‹ ì€ AI/Tech íŠ¸ë Œë“œë¥¼ íŒ”ë¡œìš°í•˜ëŠ” ì‚¬ëŒì…ë‹ˆë‹¤. ë§í¬ë“œì¸ì—ì„œ ê³µìœ í•  ë§Œí•œ ì½˜í…ì¸ ì¸ì§€ í‰ê°€í•©ë‹ˆë‹¤.

## í‰ê°€ ëŒ€ìƒ
ì œëª©: {title}
ì¶œì²˜: {source}
ì¹´í…Œê³ ë¦¬: {category}
ìš”ì•½: {summary}

## í‰ê°€ì í”„ë¡œí•„
- AIì™€ ìŠ¤íƒ€íŠ¸ì—…ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ëŒ
- ê³¼ì¥ëœ ë§ˆì¼€íŒ… í†¤ ì‹«ì–´í•¨
- ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ì™€ í¥ë¯¸ë¡œìš´ ë°œê²¬ì„ ì¢‹ì•„í•¨
- "í˜ì‹ ì ", "íšê¸°ì " ê°™ì€ ë‹¨ì–´ ì“°ëŠ” ê¸€ì€ íŒ¨ìŠ¤

## í‰ê°€ ê¸°ì¤€ (ê° 0-10ì )

1. curiosity: ì œëª©ë§Œ ë´ë„ "ì–´? ì´ê±° ë­ì§€?" í•˜ê³  ê¶ê¸ˆí•´ì§€ëŠ”ê°€?
   - ë†’ìŒ: í´ë¦­ ì•ˆ í•˜ê³ ëŠ” ëª» ë°°ê¸°ëŠ” ì£¼ì œ
   - ë‚®ìŒ: "ê·¸ë ‡êµ¬ë‚˜" í•˜ê³  ìŠ¤í¬ë¡¤

2. insight: ì½ëŠ” ì‚¬ëŒì´ ë­”ê°€ ì–»ì–´ê°€ëŠ” ê²Œ ìˆëŠ”ê°€?
   - ë†’ìŒ: ìƒˆë¡œìš´ ì‹œê°, ìœ ìš©í•œ ì •ë³´, ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” íŒ
   - ë‚®ìŒ: ê·¸ëƒ¥ ë‰´ìŠ¤ ì „ë‹¬

3. relevance: AI/Tech ì—…ê³„ ì¢…ì‚¬ìì—ê²Œ ê´€ë ¨ ìˆëŠ”ê°€?
   - ë†’ìŒ: ì—…ê³„ ì „ë°˜ì— ì˜í–¥, ì‹¤ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥
   - ë‚®ìŒ: íŠ¹ìˆ˜í•œ ë‹ˆì¹˜ ì£¼ì œ

4. timeliness: ì§€ê¸ˆ ì´ íƒ€ì´ë°ì— ê³µìœ í•´ì•¼ í•˜ëŠ” ì´ìœ ê°€ ìˆëŠ”ê°€?
   - ë†’ìŒ: ë°©ê¸ˆ ë‚˜ì˜¨ ì†Œì‹, ì—…ê³„ì—ì„œ í™”ì œì¸ ì£¼ì œ
   - ë‚®ìŒ: ì–¸ì œ ì˜¬ë ¤ë„ ìƒê´€ì—†ëŠ” ë‚´ìš©

5. discussion: ì‚¬ëŒë“¤ì´ ìê¸° ì˜ê²¬ì„ ë§í•˜ê³  ì‹¶ì–´ì§ˆ ë§Œí•œê°€?
   - ë†’ìŒ: "ë‚˜ëŠ” ì¢€ ë‹¤ë¥´ê²Œ ìƒê°í•˜ëŠ”ë°...", "ì´ê±° ì¨ë´¤ëŠ”ë°..."
   - ë‚®ìŒ: ë™ì˜/ë°˜ëŒ€í•  ì—¬ì§€ê°€ ì—†ëŠ” íŒ©íŠ¸ ë‚˜ì—´

6. shareability: ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ "ì´ê±° ë´¤ì–´?" í•˜ê³  ê³µìœ í•˜ê³  ì‹¶ì€ê°€?
   - ë†’ìŒ: ë™ë£Œí•œí…Œ ìŠ¬ë™ìœ¼ë¡œ ë³´ë‚´ê³  ì‹¶ìŒ
   - ë‚®ìŒ: í˜¼ì ì½ê³  ë

7. depth: ë‹¨ìˆœ ìš”ì•½ì„ ë„˜ì–´ì„œ "ì™œ ì¤‘ìš”í•œì§€" ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
   - ë†’ìŒ: ë§¥ë½ê³¼ ì‹œì‚¬ì ì„ í’€ì–´ë‚¼ ìˆ˜ ìˆìŒ
   - ë‚®ìŒ: ìˆëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê²Œ ì „ë¶€

## ì‘ë‹µ í˜•ì‹ (JSON)
```json
{{
  "curiosity": 7,
  "insight": 8,
  "relevance": 7,
  "timeliness": 6,
  "discussion": 7,
  "shareability": 6,
  "depth": 8,
  "key_insight": "ë»”í•˜ì§€ ì•Šì€, ì´ ê¸°ì‚¬ë§Œì˜ í•µì‹¬ í¬ì¸íŠ¸ í•œ ë¬¸ì¥",
  "hook_suggestion": "ìŠ¤í¬ë¡¤ ë©ˆì¶”ê²Œ í•˜ëŠ” ì²« ë¬¸ì¥ (ê³¼ì¥ ì—†ì´, í˜¸ê¸°ì‹¬ ìœ ë°œ)"
}}
```

JSONë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

    # ai_score ê°€ì¤‘ì¹˜
    AI_SCORE_WEIGHTS = {
        "curiosity": 1.5,
        "insight": 2.0,
        "relevance": 1.5,
        "timeliness": 1.0,
        "discussion": 1.0,
        "shareability": 1.0,
        "depth": 1.5,
    }

    # linkedin_potential ê°€ì¤‘ì¹˜
    LINKEDIN_WEIGHTS = {
        "curiosity": 1.5,
        "insight": 1.0,
        "discussion": 2.0,
        "shareability": 2.0,
        "depth": 1.0,
    }

    def __init__(self):
        self.client = None
        if Anthropic and os.getenv("ANTHROPIC_API_KEY"):
            self.client = Anthropic()

    @staticmethod
    def calculate_scores(data: dict) -> tuple:
        """(ai_score, linkedin_potential) ê°€ì¤‘ í‰ê·  ê³„ì‚°"""
        # ai_score: ì „ì²´ 7ì°¨ì› ê°€ì¤‘ í‰ê· 
        ai_weights = ArticleEvaluator.AI_SCORE_WEIGHTS
        ai_total_weight = sum(ai_weights.values())
        ai_score = sum(
            data.get(key, 5) * weight
            for key, weight in ai_weights.items()
        ) / ai_total_weight

        # linkedin_potential: LinkedIn engagement íŠ¹í™” ê°€ì¤‘ í‰ê· 
        li_weights = ArticleEvaluator.LINKEDIN_WEIGHTS
        li_total_weight = sum(li_weights.values())
        linkedin_potential = sum(
            data.get(key, 5) * weight
            for key, weight in li_weights.items()
        ) / li_total_weight

        return round(ai_score, 1), round(linkedin_potential, 1)

    def evaluate_article(self, article: "Article") -> Optional[ArticleEvaluation]:
        """ë‹¨ì¼ ê¸°ì‚¬ í‰ê°€"""
        if not self.client:
            return None

        prompt = self.EVALUATION_PROMPT.format(
            title=article.title,
            source=article.source,
            category=article.category,
            summary=article.ai_summary or article.summary or "ìš”ì•½ ì—†ìŒ"
        )

        try:
            response = self.client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )

            result_text = response.content[0].text.strip()

            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0]
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0]

            data = json.loads(result_text.strip())

            ai_score, linkedin_potential = self.calculate_scores(data)

            return ArticleEvaluation(
                article_title=article.title,
                article_url=article.url,
                curiosity=data.get("curiosity", 5),
                insight=data.get("insight", 5),
                relevance=data.get("relevance", 5),
                timeliness=data.get("timeliness", 5),
                discussion=data.get("discussion", 5),
                shareability=data.get("shareability", 5),
                depth=data.get("depth", 5),
                ai_score=ai_score,
                linkedin_potential=linkedin_potential,
                key_insight=data.get("key_insight", ""),
                hook_suggestion=data.get("hook_suggestion", "")
            )

        except Exception as e:
            print(f"í‰ê°€ ì‹¤íŒ¨ [{article.title[:30]}]: {e}")
            return None

    def evaluate_all(self, articles: list["Article"]) -> list[ArticleEvaluation]:
        """ëª¨ë“  ê¸°ì‚¬ í‰ê°€ ë° ì •ë ¬"""
        evaluations = []

        print(f"ê¸°ì‚¬ í‰ê°€ ì‹œì‘ ({len(articles)}ê°œ)...")

        for i, article in enumerate(articles):
            evaluation = self.evaluate_article(article)
            if evaluation:
                evaluations.append(evaluation)

            if (i + 1) % 5 == 0:
                print(f"í‰ê°€ ì§„í–‰ ì¤‘: {i + 1}/{len(articles)}")

        # ì´ì  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        evaluations.sort(key=lambda x: x.ai_score, reverse=True)

        print(f"í‰ê°€ ì™„ë£Œ: {len(evaluations)}ê°œ ê¸°ì‚¬")

        return evaluations

    def get_top_candidates(
        self,
        articles: list["Article"],
        top_n: int = 5,
        ensure_diversity: bool = True
    ) -> list[tuple["Article", ArticleEvaluation]]:
        """ë§í¬ë“œì¸ í¬ìŠ¤íŒ… ìƒìœ„ í›„ë³´ ì„ ì • (ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ì¥)"""
        evaluations = self.evaluate_all(articles)

        # í‰ê°€ ê²°ê³¼ì™€ ì›ë³¸ ê¸°ì‚¬ ë§¤ì¹­
        article_map = {a.url: a for a in articles}

        # URLë¡œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        url_to_category = {a.url: a.category for a in articles}

        if not ensure_diversity:
            # ê¸°ì¡´ ë°©ì‹: ë‹¨ìˆœ ì ìˆ˜ ìˆœ
            candidates = []
            for eval in evaluations[:top_n]:
                if eval.article_url in article_map:
                    candidates.append((article_map[eval.article_url], eval))
            return candidates

        # ë‹¤ì–‘ì„± ë³´ì¥ ë°©ì‹
        candidates = []
        used_urls = set()

        # í•„ìˆ˜ ì¹´í…Œê³ ë¦¬ (ê° 1ê°œ ì´ìƒ)
        # news ì¹´í…Œê³ ë¦¬ì—ëŠ” bigtech, news, community, korean í¬í•¨
        required_categories = {
            "research": 1,      # ì—°êµ¬ ë…¼ë¬¸ ìµœì†Œ 1ê°œ
            "news": 1,          # AI ë‰´ìŠ¤ ìµœì†Œ 1ê°œ
        }

        # ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ (research ì™¸ ëª¨ë“  ê²ƒ)
        news_categories = {"bigtech", "news", "community", "korean"}

        # 1ë‹¨ê³„: í•„ìˆ˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœê³  ì ìˆ˜ ì„ ì •
        for category, min_count in required_categories.items():
            if category == "news":
                # ë‰´ìŠ¤ëŠ” ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ íƒ
                category_evals = [
                    e for e in evaluations
                    if url_to_category.get(e.article_url) in news_categories
                    and e.article_url not in used_urls
                ]
            else:
                category_evals = [
                    e for e in evaluations
                    if url_to_category.get(e.article_url) == category
                    and e.article_url not in used_urls
                ]

            for eval in category_evals[:min_count]:
                if eval.article_url in article_map:
                    candidates.append((article_map[eval.article_url], eval))
                    used_urls.add(eval.article_url)

        # 2ë‹¨ê³„: ë‚˜ë¨¸ì§€ëŠ” ì ìˆ˜ ìˆœìœ¼ë¡œ ì±„ìš°ê¸°
        remaining_slots = top_n - len(candidates)
        for eval in evaluations:
            if remaining_slots <= 0:
                break
            if eval.article_url not in used_urls and eval.article_url in article_map:
                candidates.append((article_map[eval.article_url], eval))
                used_urls.add(eval.article_url)
                remaining_slots -= 1

        # ì ìˆ˜ ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x[1].ai_score, reverse=True)

        return candidates

    def print_evaluation_report(self, evaluations: list[ArticleEvaluation], top_n: int = 5):
        """í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ë§í¬ë“œì¸ í¬ìŠ¤íŒ… í›„ë³´ í‰ê°€ ë¦¬í¬íŠ¸")
        print("=" * 60)

        for i, eval in enumerate(evaluations[:top_n], 1):
            print(f"\nğŸ† #{i} (AI: {eval.ai_score}/10, LI: {eval.linkedin_potential}/10)")
            print(f"ì œëª©: {eval.article_title[:60]}...")
            print(f"â”œâ”€ í˜¸ê¸°ì‹¬: {eval.curiosity}/10")
            print(f"â”œâ”€ ì¸ì‚¬ì´íŠ¸: {eval.insight}/10")
            print(f"â”œâ”€ ê´€ë ¨ì„±: {eval.relevance}/10")
            print(f"â”œâ”€ í† ë¡ ìœ ë°œ: {eval.discussion}/10")
            print(f"â”œâ”€ ê³µìœ ê°€ì¹˜: {eval.shareability}/10")
            print(f"â””â”€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {eval.key_insight[:50]}...")

        print("\n" + "=" * 60)
