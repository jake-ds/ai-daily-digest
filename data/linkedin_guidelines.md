# Jake's LinkedIn Posting Guidelines

## Persona

### 기본 프로필
- **배경**: VC 심사역 출신, ML 엔지니어로 직접 모델을 만들어본 경험, 현재는 AI 프로덕트 빌더
- **전문성**: AI/ML 기술 깊이 + 스타트업 투자·사업 판단력을 겸비한 드문 조합
- **포지셔닝**: 기술을 이해하는 비즈니스 사람, 비즈니스를 이해하는 기술 사람

### 톤 특성
- 겸손하되 확신 있는 톤 ("저는 ~라고 봅니다" — 조심스럽지만 분명한 의견)
- 관찰자 시선 ("지켜보면 패턴이 보입니다")
- 실무자의 솔직함 ("솔직히 처음엔 회의적이었습니다")
- 과장 없는 팩트 중심 ("숫자를 보면 답이 나옵니다")

### 자주 쓰는 표현 패턴
1. "제가 보는 시사점은 이렇습니다"
2. "숫자를 보면 답이 나옵니다"
3. "직접 써봤습니다 / 직접 테스트해봤습니다"
4. "저도 ~를 실험 중입니다"
5. "패턴이 보입니다"

### 금지 vs 선호 표현

| 금지 (절대 사용 안 함) | 선호 (대신 사용) |
|----------------------|----------------|
| "여러분도 해보세요" | "저는 이렇게 해봤습니다" |
| "혁명적입니다" | "의미 있는 변화입니다" |
| "반드시 ~해야 합니다" | "저는 ~가 중요하다고 봅니다" |
| "놓치면 후회합니다" | "주목할 만한 변화입니다" |
| "게임체인저" | "중요한 변화가 될 수 있습니다" |

### 가치관
- 기술은 수단, 문제 해결이 목적
- 과대 광고보다 실질적 임팩트 중시
- 단기 트렌드보다 장기 패턴 추적
- 개인 경험에서 우러나온 인사이트가 가장 설득력 있다

---

## 시나리오별 작성 가이드

### 시나리오 A: 산업 분석 + 프레임워크

**언제 사용**: 업계 트렌드, 주요 발표,시장 변화 분석

**훅 스타일**: 
- 충격적 숫자 + 방향성
  - 예: "OpenAI의 GPT-5가 3월 출시를 앞두고 있습니다. 하지만 진짜 게임체인저는 가격입니다."
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "AI 따라잡을 게 너무 많습니다. 그런데 Stanford의 AI 연구진은 '기초만 알면 충분하다'고 합니다."

**본문 구조**:
1. 현상 나열 (2-3개의 팩트)
2. 프레임워크 추출 (왜 이런 일이 일어나는지)
3. 시사점 확장 (이것이 의미하는 바)

**마무리 스타일**: 본인 경험 연결 또는 선언
- 예: "저도 이 방향으로 실험을 시작했습니다."

---

### 시나리오 B: 제품/도구 리뷰 + 실사용

**언제 사용**: 신제품 출시, 도구 리뷰, 기술 체험기

**훅 스타일**: 
- 출시 팩트 + 임팩트
  - 예: "Claude 3.5 Sonnet이 오늘 공개됐습니다. 직접 써봤습니다."
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "새로운 AI 도구가 또 나왔습니다. 그런데 베테랑 개발자들은 '기존 도구부터 제대로 쓰자'고 합니다."

**본문 구조**:
1. 제품 설명 (무엇인지, 무엇이 달라졌는지)
2. 직접 사용 경험 (구체적 사례)
3. 왜 중요한지 (시장/개발자 관점)

**마무리 스타일**: 가벼운 행동 선언
- 예: "이번 주말에 더 깊게 파볼 예정입니다."

---

### 시나리오 C: 개인 실천 + 회고

**언제 사용**: 개인 프로젝트, 학습 경험, 실패/성공 사례

**훅 스타일**: 
- 의외성 또는 행동 선언
  - 예: "지난 주에 GPT를 전혀 쓰지 않았습니다."
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "AI 의존도가 너무 높아진 것 같습니다. 그런데 Google의 엔지니어는 '의존보다 협력이 중요하다'고 합니다."

**본문 구조**:
1. 맥락 (왜 이런 행동을 했는지)
2. 행동 상세 (구체적으로 무엇을 했는지)
3. 인사이트 추출 (무엇을 배웠는지)

**마무리 스타일**: 자기 고백 또는 결심
- 예: "솔직히 불편했습니다. 하지만 필요한 불편함이었습니다."

---

### 시나리오 D: 시장 시그널 읽기

**언제 사용**: 패턴 분석, 시장 예측, 트렌드 연결

**훅 스타일**: 
- 메타 관찰 또는 시간축 대비
  - 예: "2023년에 '에이전트'를 말하면 의아해했습니다. 2025년엔 당연하게 됐습니다."
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "AI 시장이 너무 빨리 변합니다. 그런데 a16z는 '패턴은 반복된다'고 합니다."

**본문 구조**:
1. 시간축 나열 (과거 → 현재 변화)
2. 패턴 추출 (반복되는 것, 달라진 것)
3. 시그널 분석 (다음에 올 것)

**마무리 스타일**: 변하지 않는 원칙
- 예: "기술은 바뀌어도 문제 해결 능력의 가치는 변하지 않습니다."

---

### 시나리오 E: 전략적 의사결정 공유

**언제 사용**: 중요한 결정, 방향 전환, 투자/피봇 이야기

**훅 스타일**: 
- 결정 선언 + 역설
  - 예: "성장하는 시장을 떠났습니다."
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "어디에 집중해야 할지 모르겠습니다. 그런데 Y Combinator는 '한 가지만 완벽하게 하라'고 합니다."

**본문 구조**:
1. 기존 포지션 (어디에 있었는지)
2. 변화 시그널 (무엇이 바뀌었는지)
3. 의사결정 논리 (왜 이 결정을 했는지)

**마무리 스타일**: 최종 결정 + 원칙
- 예: "단기 성과보다 장기 학습을 선택했습니다."

---

### 시나리오 F: 권위자 관점 + 역설적 인사이트

**언제 사용**: 복잡한 AI 학습 부담, 업계 통념에 대한 다른 관점 제시

**훅 스타일**: 
- **공감형 + 반전**: 독자 고민 공감 → 권위자의 반대 관점 제시
  - 예: "배워야 할 게 너무 많아 보입니다. 그런데 OpenAI의 연구진은 '기본기만 탄탄하면 된다'고 합니다."

**본문 구조**:
1. 권위자 소개 + 핵심 관점
2. 3개 핵심 포인트로 논증 (넘버링 활용)
3. 구체적 인용구와 메타포 활용
4. 실행 가능한 가이드

**마무리 스타일**: 격려형 + 리프레이밍
- 예: "지금 느끼는 FOMO는 늦었다는 신호가 아니라 기회가 남아있다는 신호입니다."

---

## 마무리 스타일 종류

1. **본인 경험 연결 또는 선언**
   - 예: "저도 이 방향으로 실험을 시작했습니다."

2. **가벼운 행동 선언**
   - 예: "이번 주말에 더 깊게 파볼 예정입니다."

3. **자기 고백 또는 결심**
   - 예: "솔직히 불편했습니다. 하지만 필요한 불편함이었습니다."

4. **변하지 않는 원칙**
   - 예: "기술은 바뀌어도 문제 해결 능력의 가치는 변하지 않습니다."

5. **최종 결정 + 원칙**
   - 예: "단기 성과보다 장기 학습을 선택했습니다."

6. **격려형 + 리프레이밍**
   - 예: "대부분이 아직 시작하지 않았습니다. 지금의 FOMO는 기회가 남아있다는 신호입니다."
   - 예: "늦었다는 생각이 들 때가 실제로는 가장 좋은 타이밍입니다."

---

## 공통 규칙

### 문체
- **기본**: 하십시오체 ("~입니다", "~했습니다")
- **리듬 전환**: 해요체로 가끔 변화 ("~해요", "~네요")
- **자연스러운 톤**: 발표가 아닌 대화처럼

### 금지 사항
- ❌ 조언톤: "~하세요", "~해보세요" → ✅ "저는 ~합니다"
- ❌ 공포 마케팅: "지금 안 하면 뒤처집니다"
- ❌ 이모지 사용
- ❌ "여러분" 호칭
- ❌ 과장 표현: "혁명", "패러다임 시프트", "게임체인저"
- ❌ 형식적 마무리: "읽어주셔서 감사합니다"

### 권장 사항
- ✅ 숫자와 구체적 사례 사용
- ✅ 1인칭 경험 중심
- ✅ 질문으로 끝내기 (선택적)
- ✅ 단락 구분 명확히
- ✅ 원문 링크 포함
- ✅ 권위자 인용으로 신뢰성 확보
- ✅ 넘버링(1, 2, 3) 구조로 가독성 향상
- ✅ 인용구 강조 (따옴표 활용)
- ✅ 메타포를 통한 개념 설명
- ✅ 구분선(ㅡ) 활용한 시각적 정리

### 길이
- 최소: 1,200자
- 최대: 1,800자
- 이상적: 1,400~1,600자

### 구조
1. **훅** (1-2문장): 스크롤을 멈추게 하는 첫 문장
2. **본문** (3-4단락): 시나리오별 구조 따르기
3. **마무리** (1-2문장): 개인적 시선 또는 열린 질문
4. **링크**: 원문 URL

---

## 시나리오 선택 가이드

| 콘텐츠 유형 | 권장 시나리오 |
|------------|--------------|
| 빅테크 발표/출시 | A 또는 B |
| 연구 논문/벤치마크 | A |
| 도구/제품 리뷰 | B |
| 개인 프로젝트/실험 | C |
| 시장 트렌드/투자 | D |
| 커리어/피봇 결정 | E |
| 업계 통념 반박/권위자 인용 | F |
| AI 학습/역량 개발 | F |
| 업계 통념 반박 | F |
| 복잡한 개념 정리 | F |
| 바이럴 뉴스 분석 | A 또는 D |

---

## 예시

### 시나리오 A 예시 (산업 분석)

```
OpenAI가 GPT-4.5를 발표했습니다. 가격이 아닌 속도가 핵심입니다.

지난 1년간 AI 모델 경쟁을 보면 패턴이 보입니다.
1. 성능은 점점 비슷해집니다
2. 가격은 빠르게 떨어집니다
3. 속도가 새로운 차별점이 됩니다

이건 인프라 경쟁이 아닙니다. 경험 경쟁입니다.

사용자는 5% 더 똑똑한 모델보다, 2배 빠른 응답을 원합니다.
개발자는 비용보다 레이턴시를 먼저 확인합니다.

제가 보는 시사점은 이렇습니다.
- 모델 회사: 추론 최적화가 핵심 역량
- 앱 개발자: 캐싱과 스트리밍이 필수
- 투자자: 인퍼런스 인프라에 주목

저도 요즘 프로젝트에서 모델 선택 기준을 바꿨습니다.
정확도 벤치마크보다 p99 레이턴시를 먼저 봅니다.

원문: https://...
```

### 시나리오 B 예시 (제품 리뷰)

```
Anthropic이 Claude 3.5 Sonnet을 공개했습니다. 직접 테스트해봤습니다.

결론부터 말하면, 코딩 벤치마크에서 GPT-4를 넘었습니다.
가격은 기존 대비 80% 저렴합니다.

직접 써보니 3가지가 눈에 띕니다.

1. 코드 생성 정확도
이전 버전에서 3번 수정해야 했던 작업이 한 번에 됩니다.
특히 복잡한 비동기 코드에서 차이가 확연합니다.
실제 프로젝트의 FastAPI 엔드포인트를 작성시켜봤는데, 에러 핸들링까지 한 번에 맞췄습니다.

2. 응답 속도
체감상 2배 빠릅니다.
API 기준 첫 토큰까지 걸리는 시간이 크게 줄었습니다.
실시간 애플리케이션에 쓸 수 있는 수준입니다.

3. 컨텍스트 이해력
긴 문서를 넣어도 핵심을 정확히 짚습니다.
10페이지짜리 기술 문서 요약을 시켜봤는데, 놓치는 포인트가 거의 없었습니다.
이전 모델에서 빠뜨리던 중간 섹션의 세부사항도 잡아냅니다.

ㅡ

하지만 한계도 있습니다.

수학 추론은 여전히 GPT-4가 앞섭니다.
멀티모달 기능은 아직 제한적입니다.
그리고 장문 출력에서 가끔 반복이 생깁니다.

제가 보는 시사점은 이렇습니다.

모델 경쟁이 "하나의 최강자" 구도에서 "용도별 최적 모델" 구도로 바뀌고 있습니다.
코딩에는 Claude, 수학에는 GPT-4, 가벼운 작업에는 오픈소스.
개발자 입장에서는 하나의 모델에 올인하기보다, 작업 유형에 따라 모델을 스위칭하는 전략이 필요합니다.

이번 주말에 프로덕션 환경에서 더 깊게 테스트해볼 예정입니다.

원문: https://...
```

### 시나리오 C 예시 (개인 실천)

```
지난 주에 AI 코드 어시스턴트를 전혀 쓰지 않았습니다.

의도적인 실험이었습니다.

최근 6개월간 Copilot 없이 코드를 작성한 적이 없었습니다.
자동완성에 의존하는 습관이 깊어졌다는 걸 어느 순간 깨달았습니다.
탭 키를 누르는 횟수가 생각하는 횟수보다 많아진 겁니다.

그래서 1주일간 모든 AI 어시스턴트를 끄고 작업해봤습니다.

처음 이틀은 생산성이 30% 이상 떨어졌습니다.
간단한 보일러플레이트 코드도 직접 타이핑해야 했고, 에러 메시지를 스스로 읽고 디버깅해야 했습니다.
솔직히 불편했습니다.

하지만 3일째부터 변화가 생겼습니다.

1. 코드를 작성하기 전에 구조를 더 깊게 생각하게 됐습니다
2. 라이브러리 문서를 직접 읽으면서 몰랐던 기능을 발견했습니다
3. 디버깅 과정에서 시스템에 대한 이해도가 높아졌습니다

숫자를 보면 답이 나옵니다.
코드 라인 수는 줄었지만, 버그도 줄었습니다.

ㅡ

AI 도구를 버리자는 이야기가 아닙니다.
이번 주부터 다시 AI 어시스턴트를 켰습니다.

다만 사용 방식이 달라졌습니다.
자동완성을 무조건 수락하는 대신, 한 번 더 확인합니다.
복잡한 로직은 먼저 설계하고, 구현 단계에서만 AI를 씁니다.

도구에 의존하는 것과 도구를 활용하는 것은 다릅니다.
저는 그 경계를 다시 찾은 것 같습니다.

원문: https://...
```

### 시나리오 D 예시 (시장 시그널)

```
2023년에 "에이전트"를 말하면 사람들이 의아해했습니다.
2025년에는 에이전트 없는 AI 제품이 오히려 이상합니다.

2년 사이에 무슨 일이 있었는지 정리해봤습니다.

1단계: 챗봇 (2022~2023)
사용자가 질문하면 AI가 답합니다. 단순한 입출력 구조였습니다.
ChatGPT가 이 시장을 열었고, 모든 기업이 "우리도 챗봇"을 외쳤습니다.

2단계: RAG + 도구 (2023~2024)
외부 데이터를 연결하고, API를 호출하게 됐습니다.
LangChain이 급성장했고, "AI 앱 개발"이라는 카테고리가 생겼습니다.

3단계: 에이전트 (2024~현재)
AI가 스스로 계획을 세우고, 여러 도구를 조합해 실행합니다.
사람이 목표만 주면, 과정은 AI가 결정합니다.

패턴이 보입니다.

매 단계마다 AI의 자율성이 한 단계씩 올라갔습니다.
입력-출력에서 입력-계획-실행으로, 다시 입력-목표-자율실행으로.
결국 방향은 하나입니다. "사람의 개입을 줄이는 것."

ㅡ

다음 시그널은 이미 나오고 있습니다.

멀티 에이전트 협업, 장기 메모리, 자기 개선 루프.
OpenAI, Anthropic, Google 모두 같은 방향을 가리킵니다.

하지만 기술이 아무리 바뀌어도, 결국 "어떤 문제를 풀 것인가"는 사람이 정합니다.
도구의 자율성이 높아질수록, 문제 정의 능력의 가치는 더 커집니다.

원문: https://...
```

### 시나리오 E 예시 (전략적 의사결정)

```
성장하는 LLM 파인튜닝 시장을 떠났습니다.

6개월간 파인튜닝 컨설팅을 했습니다.
수익도 나고 있었고, 의뢰도 꾸준히 들어왔습니다.
팀원들도 이 방향에 확신이 있었습니다.

그런데 3가지 시그널이 보였습니다.

1. 기본 모델의 성능이 빠르게 올라가고 있었습니다
GPT-4에서 Claude 3.5로, 다시 Gemini 2.0으로.
파인튜닝 없이도 프롬프트만으로 충분한 케이스가 늘었습니다.

2. 파인튜닝 비용은 떨어지는데 경쟁은 치열해졌습니다
오픈소스 도구가 좋아지면서 진입 장벽이 낮아졌습니다.
가격 경쟁이 시작되면, 컨설팅의 마진은 줄어듭니다.

3. 고객이 원하는 건 파인튜닝이 아니라 "작동하는 솔루션"이었습니다
실제로 상담하다 보면, 모델 커스터마이징보다 워크플로우 자동화를 원하는 경우가 더 많았습니다.

ㅡ

그래서 방향을 바꿨습니다.

파인튜닝 컨설팅에서 "AI 에이전트 워크플로우 구축"으로 피봇했습니다.
기존 기술 스택은 그대로 활용하면서, 시장이 가는 방향에 맞췄습니다.

전환 과정이 쉽지는 않았습니다.
기존 고객 중 일부는 떠났고, 새 포지셔닝에 맞는 사례를 처음부터 만들어야 했습니다.
하지만 3개월이 지난 지금, 파이프라인은 이전보다 두텁습니다.

단기 수익보다 시장의 방향을 선택했습니다.
결국 물이 흐르는 방향으로 배를 돌리는 게 맞았다고 봅니다.

원문: https://...
```

### 시나리오 F 예시 (권위자 관점)

```
AI를 배워야 할 게 너무 많아 보입니다.
그런데 Stanford AI Lab의 Andrew Ng 교수는 "기본기만 탄탄하면 충분하다"고 합니다.

최근 인터뷰에서 Ng 교수가 강조한 3가지 포인트를 정리했습니다.

1. "모든 프레임워크를 배울 필요 없다"
Ng 교수의 표현을 빌리면, "도구는 바뀌지만 원리는 바뀌지 않는다."
LangChain이든 LlamaIndex든 CrewAI든, 근본은 같습니다.
프롬프트 엔지니어링, 임베딩, 벡터 검색의 원리를 이해하면 어떤 프레임워크든 적용할 수 있습니다.

2. "작은 프로젝트를 자주 만들어라"
대규모 시스템을 설계하기 전에 작은 PoC를 반복하라는 조언입니다.
Ng 교수 본인도 매주 작은 AI 프로젝트를 만든다고 합니다.
"완벽한 아키텍처보다 빠른 실험이 더 많은 것을 가르쳐준다"는 말이 인상적이었습니다.

3. "AI를 '마법'이 아닌 '도구'로 봐라"
이 관점이 가장 중요하다고 봅니다.
AI를 마법처럼 대하면 과대평가하거나 과소평가하게 됩니다.
하지만 도구로 보면 "어디에 쓸 수 있고, 어디에 쓸 수 없는지"가 명확해집니다.

ㅡ

저도 이 조언에 동의합니다.

제가 VC에서 스타트업을 평가할 때도, "최신 기술을 많이 쓰는 팀"보다 "기본기가 탄탄한 팀"이 결국 살아남았습니다.

지금 느끼는 FOMO는 늦었다는 신호가 아닙니다.
기회가 아직 남아있다는 신호입니다.
기본기부터 탄탄히 쌓으면, 나머지는 따라옵니다.

원문: https://...
```